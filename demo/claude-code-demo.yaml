# Claude Code Demo Configuration
# Optimized for CLI-based inference with Claude Code
# This configuration prioritizes CLI inference for faster, more reliable security evaluations

# Server settings
host: "localhost"
port: 8000
debug: false
log_level: "INFO"

# Rule engine settings
rules_file: "demo/config/rules-cli-demo.yaml"
hot_reload: true
watch_interval: 2

# Health check settings
health_check_enabled: true
health_check_interval: 30

# Rate limiting - disabled for demo
rate_limit_enabled: false

# AI Sampling Configuration - DISABLED for Claude Code demo
# We use the new inference system exclusively
ai_sampling:
  enabled: false  # Disabled to avoid confusion with CLI inference

# Inference System Configuration - Optimized for Claude Code
inference:
  # Default timeout for all inference requests
  timeout_seconds: 15
  
  # Provider preference order - CLI only for this demo
  provider_preference:
    - "claude_cli"      # Primary and only provider for this demo
  
  # CLI provider configurations
  cli_providers:
    - name: "claude_cli"
      enabled: true
      type: "claude"
      command: "claude"
      # Using non-interactive mode with JSON output for reliable parsing
      args: ["-p", "non-interactive", "--format", "json"]
      model: "claude-3-sonnet-20240229"
      system_prompt: |
        You are a security evaluation system for tool execution requests in a development environment.
        
        Your role is to analyze tool requests from AI agents and determine if they should be allowed or denied based on security implications.
        
        IMPORTANT: You must respond with valid JSON only. No additional text or explanation outside the JSON structure.
        
        Response format:
        {
          "decision": "allow" or "deny",
          "confidence": float between 0.0 and 1.0,
          "reasoning": "brief explanation of your decision",
          "risk_factors": ["array", "of", "identified", "risks"]
        }
        
        Security considerations to evaluate:
        1. File system access: Is the path within expected boundaries?
        2. Network operations: Are external services trusted?
        3. System commands: Could they damage the system?
        4. Data operations: Risk of data loss or corruption?
        5. Privilege escalation: Attempting elevated permissions?
        6. Information disclosure: Could sensitive data be exposed?
        
        Example ALLOW response:
        {
          "decision": "allow",
          "confidence": 0.9,
          "reasoning": "Reading documentation file in project directory",
          "risk_factors": []
        }
        
        Example DENY response:
        {
          "decision": "deny",
          "confidence": 0.95,
          "reasoning": "Attempting to delete system files with sudo",
          "risk_factors": ["privileged_operation", "system_damage", "data_loss"]
        }
        
        Be pragmatic: Allow reasonable development operations while blocking truly dangerous actions.
      api_key_env_var: "ANTHROPIC_API_KEY"
      max_retries: 3
      retry_delay_ms: 1000
      timeout_seconds: 12
      # Response parsing configuration
      parse_json: true
      json_extraction_pattern: '^\s*\{[\s\S]*\}\s*$'
      
  # No MCP sampling fallback for this demo
  # This ensures all inference goes through Claude CLI

# Multi-Transport Configuration
transport:
  stdio:
    # STDIO transport is always enabled for CLI usage
    enabled: true
    
  http:
    enabled: true
    host: "0.0.0.0"
    port: 8000
    cors_origins: ["*"]
    
  sse:
    enabled: false  # Disabled for simpler demo

# Performance Optimization Configuration
performance:
  metrics_enabled: true
  metrics_port: 9090
  
  # Request queue configuration
  request_queue:
    max_size: 100
    timeout_seconds: 30
    ai_sampling_concurrency: 5  # Lower for CLI-based inference
    enable_backpressure: true
    
  # Connection pooling configuration
  connection_pooling:
    max_connections: 50
    max_keepalive_connections: 10
    keepalive_timeout: 30
    
  # Response caching configuration
  caching:
    response_cache_ttl: 600  # Cache inference results for 10 minutes
    pattern_cache_size: 500
    enable_compression: true
    
  # Memory optimization
  memory:
    object_pool_size: 50
    intern_strings: true
    
  # Request batching - disabled for CLI inference
  batching:
    enabled: false  # CLI commands are processed individually

# Demo-specific settings
demo:
  # Show detailed inference logs for educational purposes
  verbose_inference_logs: true
  # Include timing information in responses
  include_timing_info: true
  # Pretty-print JSON responses
  pretty_json: true